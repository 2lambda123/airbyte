{
  "documentationUrl": "https://docs.airbyte.com/integrations/destinations/langchain",
  "supported_destination_sync_modes": [
    "overwrite", "append"
  ],
  "supportsIncremental": true,
  "connectionSpecification": {
    "$schema": "http://json-schema.org/draft-07/schema#",
    "title": "Destination Langchain",
    "type": "object",
    "required": [],
    "additionalProperties": false,
    "properties": {
      "processing": {
        "type": "object",
        "title": "Processing",
        "group": "processing",
        "required": [
          "chunk_size"
        ],
        "properties": {
            "chunk_size": {
              "type": "integer",
              "title": "Chunk size",
              "maximum": 8191,
              "description": "Size of chunks in tokens to store in vector store (make sure it is not too big for the context if your LLM)"
            },
            "chunk_overlap": {
              "type": "integer",
              "title": "Chunk overlap",
              "description": "Size of overlap between chunks in tokens to store in vector store to better capture relevant context"
            },
            "text_fields": {
              "type": "array",
              "title": "Text fields to embed",
              "description": "List of fields in the record that should be used to calculate the embedding. All other fields are passed along as meta fields. If none are defined, all fields are considered text fields"
            }
        }
      },
      "embedding": {
        "type": "object",
        "group": "embedding",
        "title": "Embedding",
        "description": "Configure how to pre-process the data (chunking and embedding)",
        "oneOf": [
          {
            "type": "object",
            "title": "OpenAI",
            "required": [
              "mode",
              "openai_key"
            ],
            "properties": {
              "mode": {
                "const": "openai"
              },
              "openai_key": {
                "type": "string",
                "airbyte_secret": true,
                "title": "OpenAI API key"
              }
            }
          }
        ]
      },
      "storing": {
        "type": "object",
        "group": "storing",
        "title": "Database provider",
        "description": "Configure how to store the embeddings",
        "oneOf": [
          {
            "type":"object",
            "title": "Pinecone",
            "properties": {
              "mode": {
                "const": "pinecone"
              },
              "pinecone_key": {
                "type": "string",
                "airbyte_secret": true,
                "title": "Pinecone API key"
              },
              "pinecone_environment": {
                "type": "string",
                "title": "Pinecone environment",
                "description": "Pinecone environment to use"
              },
              "index": {
                "type": "string",
                "title": "Index",
                "description": "Pinecone index to use"
              }
            }
          },
          {
            "type":"object",
            "title": "DocArrayHnswSearch",
            "description": "DocArrayHnswSearch is a lightweight Document Index implementation provided by Docarray that runs fully locally and is best suited for small- to medium-sized datasets. It stores vectors on disk in hnswlib, and stores all other data in SQLite.",
            "required": [
              "destination_path"
            ],
            "properties": {
              "mode": {
                "const": "DocArrayHnswSearch"
              },
              "destination_path": {
                "description": "Path to the directory where hnswlib and meta data files will be written. The files will be placed inside that local mount.",
                "title": "Destination Path",
                "type": "string",
                "examples": ["/json_data"]
              }
            }
          }
        ]
      }
    },
    "groups": [
      {
        "id": "processing",
        "title": "Processing"
      },
      {
        "id": "embedding",
        "title": "Embedding"
      },
      {
        "id": "storing",
        "title": "Indexing"
      }
    ]
  }
}
